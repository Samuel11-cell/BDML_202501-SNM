{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952ad54-2218-4382-b2eb-d401d349f764",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65198d8b",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ignaciomsarmiento/BDML_202501/blob/main/Modulo05/CuadernoModulo05_Boosting.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1732bc",
   "metadata": {},
   "source": [
    "# Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0ac10-34c0-4764-ba2e-2ac012e76d0b",
   "metadata": {},
   "source": [
    "Cargamos los paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01836b98-89c2-409b-b842-e4b0fc4cb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"pacman\") #run this line if you use Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10565d-df2e-4513-bef6-de572c22722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "require(\"pacman\")\n",
    "p_load(\"tidyverse\",\"ggplot2\",\"rpart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf08af-fdc2-43a5-abc7-0e6ffccb713e",
   "metadata": {},
   "source": [
    "## Motivation: Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b987eda-16c0-434c-9aa0-9d9b2e0db794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db<-read.csv(\"https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/boosting_tree_toy.csv\")\n",
    "head(db)\n",
    "\n",
    "y<-db$y\n",
    "x<-db$x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d43764-3fc5-42d7-a8f1-6774e9b9fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9142613-03ce-4fdd-907d-a6b44b3f3329",
   "metadata": {},
   "source": [
    "## Algoritmo\n",
    "\n",
    "\n",
    "\n",
    "<small>\n",
    "\n",
    "1. Iniciamos fijando $\\hat{f}(x) = 0$ y $r_i = y_i$ para todos los $i$ del *training set*  \n",
    "2. Para $m = 1, 2, \\dots, M$  \n",
    "    a. Ajustamos un árbol $\\hat{f}^m(x)$ con $J$ bifurcaciones  \n",
    "    b. Actualizamos $\\hat{f}(x)$  \n",
    "    $$\n",
    "    \\hat{f}(x) \\leftarrow \\hat{f}(x) + \\lambda \\hat{f}^m(x)\n",
    "    $$  \n",
    "c. Actualizamos los residuales  \n",
    "    $$\n",
    "    r_i \\leftarrow r_i - \\lambda \\hat{f}^m(x)\n",
    "    $$  \n",
    "3. El modelo final es  \n",
    "    $$\n",
    "    \\hat{f}_{boost} = \\sum_{m=1}^M \\lambda \\hat{f}^m(x)\n",
    "    $$\n",
    "\n",
    "\n",
    "\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df95e01c-0707-4cb7-a125-77808ebb980c",
   "metadata": {},
   "source": [
    "### Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2516622-3307-40d9-9de8-f1e527ee1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda<-.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ca540-26e7-42a4-abb7-a2967bb78054",
   "metadata": {},
   "outputs": [],
   "source": [
    "J<-1 #stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d18e4-5aff-4a19-9695-0c7df9efbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65edff6e-c8c8-4d1c-a900-c34a6ed96f47",
   "metadata": {},
   "source": [
    "### Iniciamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5847b9-66e1-4bd8-8e4f-692718081924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fhat=rep(0,length(y))\n",
    "\n",
    "r=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba215e1d-bd1c-4396-8b19-9d60e94dc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7132ac-35f1-4cbc-a58e-7f80a1b3cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5516da-d808-4c28-a535-f8d55603c5ef",
   "metadata": {},
   "source": [
    "###  Primera iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748052a-6381-456b-80e8-378dade68ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit1<-rpart(r ~ x, control = list(maxdepth = J))\n",
    "yhat1<-predict(fit1,newdata=data.frame(x))\n",
    "\n",
    "head(lambda *yhat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82c76d-bb21-4f56-8332-4d5d2008a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1<-fhat + lambda *yhat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbf7ef-89c6-426b-a8f2-2c2afe912100",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x,y,ylab=\"\",xlab=\"\")\n",
    "lines(x,f1,type=\"s\",col=\"red\",lwd=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113009b-b2f4-43e3-b985-e91cc1b2d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1<- r - lambda*yhat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67cb58-0481-4293-99b9-e2be60858f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Segunda Iteracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c010c10-9cbd-46e5-9fb0-2f84f9dc62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit2<-rpart(r1 ~ x, control = list(maxdepth = J))\n",
    "yhat2<-predict(fit2,newdata=data.frame(x))\n",
    "f2<- f1 + lambda *yhat2\n",
    "\n",
    "head(lambda *yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0dfd3-e094-4478-bcd8-6f27d643fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x,y,ylab=\"\",xlab=\"\")\n",
    "lines(x,f2,type=\"s\",col=\"red\",lwd=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb56a78-7212-45b7-8f3b-34b73ff72e5e",
   "metadata": {},
   "source": [
    "# El algoritmo Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2474b2-e787-4d5a-a8a0-8d6cfdfe93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M<- 1000\n",
    "\n",
    "# En un loop\n",
    "fhat<-rep(0,length(y))\n",
    "\n",
    "r = y\n",
    "\n",
    "YP<-lambda*fhat\n",
    "\n",
    "for(t in 1:M){\n",
    "  fit <- rpart(r~x, control = list(maxdepth = 1))\n",
    "  yhat<- predict(fit,newdata=data.frame(x))\n",
    "  r <-  r - lambda*yhat\n",
    "  YP <-  cbind(YP,lambda*yhat)}\n",
    "\n",
    "head(YP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b2364-81e4-4617-ac65-cbe9ad7c5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhat<-apply(YP[,1:M],1,sum)\n",
    "\n",
    "plot(x,y,ylab=\"\",xlab=\"\")\n",
    "lines(x,fhat,type=\"s\",col=\"red\",lwd=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8827c02-e86e-48c4-98e1-1b83c3b6ffc9",
   "metadata": {},
   "source": [
    "## Gradient Boosting en el Ames Data Set\n",
    "\n",
    "\n",
    "Este conjunto de datos contiene información detallada sobre las características de viviendas en Ames, Iowa, y su precio de venta. Incluye más de 80 variables que describen aspectos físicos, de ubicación y de calidad de las propiedades, como el tamaño habitable, el tipo de edificio, el año de construcción, el número de baños, y si tiene garaje o cercado, entre otros.\n",
    "\n",
    "Es ampliamente utilizado en ciencia de datos y machine learning como un caso realista para problemas de regresión.  \n",
    "La descripción completa de las variables puede consultarse aquí:  \n",
    "https://jse.amstat.org/v19n3/decock/DataDocumentation.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ab990-ee46-46bb-9890-dd5f1a58ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_load(\"modeldata\")\n",
    "\n",
    "data(\"ames\", package = \"modeldata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735668e-e2c0-4c59-a44c-b575c847d6a9",
   "metadata": {},
   "source": [
    "En este ejemplo, vamos a usar Gradient Boosting Machines (GBM) para modelar el precio de venta de las viviendas a partir de algunas de sus características. \n",
    "\n",
    "Primero cargamos los paquetes necesarios. caret nos permite entrenar y validar modelos de manera unificada, mientras que gbm implementa el algoritmo de Gradient Boosting Machines que usaremos en este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a4d77-6d92-4e6a-adaa-c481a7288c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_load(\"caret\")\n",
    "p_load('gbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481436d-624e-4d87-aba1-de6c1965e712",
   "metadata": {},
   "source": [
    "El rendimiento del modelo GBM depende fuertemente de la elección de sus hiperparámetros:\n",
    "\n",
    "- n.trees (# Boosting Iterations) $M$\n",
    "- interaction.depth (Max Tree Depth) $J$\n",
    "- shrinkage (Shrinkage) $\\lambda$\n",
    "- n.minobsinnode (Min. Terminal Node Size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a03ec",
   "metadata": {},
   "source": [
    "Definimos la grilla de entrenamiento de los hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gbm<-expand.grid(n.trees=c(200,300,500),\n",
    "                      interaction.depth=c(4,6),\n",
    "                      shrinkage=c(0.001,0.01),\n",
    "                      n.minobsinnode = c(10,30))\n",
    "\n",
    "\n",
    "grid_gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitControl<-trainControl(method =\"cv\",\n",
    "                         number=5)\n",
    "\n",
    "\n",
    "set.seed(1011)\n",
    "gbm_tree <- train( log(Sale_Price) ~ Gr_Liv_Area  + Bldg_Type + Fence,\n",
    "    data=ames,\n",
    "  method = \"gbm\", \n",
    "  trControl = fitControl,\n",
    "  tuneGrid=grid_gbm,\n",
    "  verbose = FALSE\n",
    ")            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e630439",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0177d",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}=\\sum_{i=1}^{N}L(y_{i},\\sum_{m=1}^{M}T(x_{i};\\Theta_{m}))+\\sum_{m=1}^{M}\\left(\\zeta J+\\frac{1}{2}\\varphi\\sum_{j=1}^{J}\\gamma_{j}^{2} \\right)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20b071-d7bb-42f4-9b19-61b756c37862",
   "metadata": {},
   "source": [
    "﻿Para entrenar modelos con **XGBoost**, primero cargamos el paquete correspondiente: `xgboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_load('xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade69ca2",
   "metadata": {},
   "source": [
    "R nos permite \"tunear\" los siguientes hiperparámetros:\n",
    "\n",
    "- `nrounds`: número de árboles (o iteraciones) en el modelo.\n",
    "- `max_depth`: profundidad máxima de cada árbol, controla la complejidad del modelo.\n",
    "- `eta`: tasa de aprendizaje (*shrinkage*), regula cuánto ajusta cada árbol.\n",
    "- `min_child_weight`: número mínimo de observaciones por nodo terminal.\n",
    "- `colsample_bytree`: fracción de columnas que se usan al construir cada árbol.\n",
    "- `subsample`: fracción de observaciones que se usan al construir cada árbol.\n",
    "\n",
    "Notemos que la formulación teórica del modelo incluye más parámetros (como el número de ramas o la regularización L1), **no todos ellos están disponibles o son fácilmente tuneables a través de la interfaz de `caret` en R**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9243c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xbgoost <- expand.grid(nrounds = c(250),\n",
    "                            max_depth = c(4), \n",
    "                            eta = c(0.01), \n",
    "                            gamma = c(0), \n",
    "                            min_child_weight = c(10, 25),\n",
    "                            colsample_bytree = c(0.33,0.66),\n",
    "                            subsample = c(0.4))\n",
    "\n",
    "grid_xbgoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1011)\n",
    "\n",
    "Xgboost_tree <- train(log(Sale_Price) ~ Gr_Liv_Area  + Bldg_Type + Fence,\n",
    "    data=ames,\n",
    "  method = \"xgbTree\", \n",
    "  trControl = fitControl,\n",
    "  tuneGrid=grid_xbgoost\n",
    ")        \n",
    "\n",
    "Xgboost_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2963f23",
   "metadata": {},
   "source": [
    "\n",
    "Es importante tener en cuenta que **nunca existe una única elección óptima de hiperparámetros que funcione bien en todos (o incluso en la mayoría) de los casos**. De hecho, la elección de un hiperparámetro suele influir de manera significativa en el valor óptimo de otros hiperparámetros. Generalmente, hay compensaciones importantes que considerar entre los distintos valores posibles.\n",
    "\n",
    "Por ejemplo, en el caso de **XGBoost**, un valor alto de `min_child_weight` puede requerir una reducción en `eta` o en `max_depth` para lograr un buen desempeño. \n",
    "\n",
    "Este tipo de interdependencia también se presenta en varios algoritmos de ML.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
